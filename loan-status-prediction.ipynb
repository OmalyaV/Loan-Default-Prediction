{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7653020,"sourceType":"datasetVersion","datasetId":4461571}],"dockerImageVersionId":30646,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-25T19:38:52.843483Z","iopub.execute_input":"2024-02-25T19:38:52.843901Z","iopub.status.idle":"2024-02-25T19:38:52.863612Z","shell.execute_reply.started":"2024-02-25T19:38:52.843867Z","shell.execute_reply":"2024-02-25T19:38:52.862326Z"},"trusted":true},"execution_count":71,"outputs":[{"name":"stdout","text":"/kaggle/input/debt-default-prediction/X_test.csv\n/kaggle/input/debt-default-prediction/DataDictionary.xlsx\n/kaggle/input/debt-default-prediction/valid.csv\n/kaggle/input/debt-default-prediction/train.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Train dataset is read and the rows with missing target value is removed from the dataset.","metadata":{}},{"cell_type":"code","source":"X_train = pd.read_csv('/kaggle/input/debt-default-prediction/train.csv')\nX_train.dropna(axis=0, subset=['loan_status'], inplace=True)\nX_train.head()\ny_train = X_train.loan_status\nX_train.drop(['loan_status'], axis = 1,inplace= True )\n","metadata":{"execution":{"iopub.status.busy":"2024-02-25T19:38:52.865750Z","iopub.execute_input":"2024-02-25T19:38:52.866315Z","iopub.status.idle":"2024-02-25T19:39:03.791440Z","shell.execute_reply.started":"2024-02-25T19:38:52.866281Z","shell.execute_reply":"2024-02-25T19:39:03.790158Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"print(X_train.shape)\nmissing_val_count_by_column = (X_train.isnull().sum())\nprint(missing_val_count_by_column[missing_val_count_by_column >0])","metadata":{"execution":{"iopub.status.busy":"2024-02-25T19:39:03.795485Z","iopub.execute_input":"2024-02-25T19:39:03.796415Z","iopub.status.idle":"2024-02-25T19:39:04.571092Z","shell.execute_reply.started":"2024-02-25T19:39:03.796379Z","shell.execute_reply":"2024-02-25T19:39:04.569982Z"},"trusted":true},"execution_count":73,"outputs":[{"name":"stdout","text":"(517788, 144)\nid                       517788\nmember_id                517788\nemp_title                 34051\nemp_length                31300\nurl                      517788\n                          ...  \nsettlement_status        498528\nsettlement_date          498528\nsettlement_amount        498528\nsettlement_percentage    498528\nsettlement_term          498528\nLength: 104, dtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"num_cols_with_missing = (missing_val_count_by_column >50000).sum()\nnum_cols_with_missing","metadata":{"execution":{"iopub.status.busy":"2024-02-25T19:39:04.575339Z","iopub.execute_input":"2024-02-25T19:39:04.575692Z","iopub.status.idle":"2024-02-25T19:39:04.583170Z","shell.execute_reply.started":"2024-02-25T19:39:04.575663Z","shell.execute_reply":"2024-02-25T19:39:04.582039Z"},"trusted":true},"execution_count":74,"outputs":[{"execution_count":74,"output_type":"execute_result","data":{"text/plain":"59"},"metadata":{}}]},{"cell_type":"code","source":"# Identify columns with more than 50,000 missing values\ncols_to_drop = missing_val_count_by_column[missing_val_count_by_column > 50000].index\n\n# Ensure that the columns to drop actually exist in X_train\ncols_to_drop = [col for col in cols_to_drop if col in X_train.columns]\n\n# Drop columns from X_train\nX_train.drop(cols_to_drop, axis=1, inplace=True)\n\n# Print the shape of X_train after dropping columns\nprint(X_train.shape)","metadata":{"execution":{"iopub.status.busy":"2024-02-25T19:39:04.584831Z","iopub.execute_input":"2024-02-25T19:39:04.585283Z","iopub.status.idle":"2024-02-25T19:39:04.833092Z","shell.execute_reply.started":"2024-02-25T19:39:04.585244Z","shell.execute_reply":"2024-02-25T19:39:04.831961Z"},"trusted":true},"execution_count":75,"outputs":[{"name":"stdout","text":"(517788, 85)\n","output_type":"stream"}]},{"cell_type":"code","source":"X_valid = pd.read_csv('/kaggle/input/debt-default-prediction/valid.csv')\nX_valid.dropna(axis=0, subset=['loan_status'], inplace=True)\n\ny_valid = X_valid.loan_status\nX_valid.drop(['loan_status'], axis = 1,inplace= True )\ntrain_columns  = X_train.columns\nX_valid = X_valid[train_columns]\nX_valid.shape","metadata":{"execution":{"iopub.status.busy":"2024-02-25T19:39:04.837041Z","iopub.execute_input":"2024-02-25T19:39:04.837421Z","iopub.status.idle":"2024-02-25T19:39:08.244419Z","shell.execute_reply.started":"2024-02-25T19:39:04.837390Z","shell.execute_reply":"2024-02-25T19:39:08.243392Z"},"trusted":true},"execution_count":76,"outputs":[{"execution_count":76,"output_type":"execute_result","data":{"text/plain":"(172596, 85)"},"metadata":{}}]},{"cell_type":"markdown","source":"* **Let us handle the rest of the missing values with imputations , numerical values with the mean of the column and the object columns with the most frequent value.**","metadata":{}},{"cell_type":"code","source":"unique_values_counts = X_train.nunique()\n\n# Find columns where number of unique values is equal to 1\ncolumns_with_same_value = unique_values_counts[unique_values_counts == 1].index.tolist()\n\n# Print columns with the same value for every entry\n\nX_train = X_train.drop(columns=columns_with_same_value)\nX_valid = X_valid.drop(columns=columns_with_same_value)\nprint(X_train.shape, X_valid.shape)","metadata":{"execution":{"iopub.status.busy":"2024-02-25T19:39:08.245856Z","iopub.execute_input":"2024-02-25T19:39:08.246422Z","iopub.status.idle":"2024-02-25T19:39:09.802720Z","shell.execute_reply.started":"2024-02-25T19:39:08.246392Z","shell.execute_reply":"2024-02-25T19:39:09.800893Z"},"trusted":true},"execution_count":77,"outputs":[{"name":"stdout","text":"(517788, 80) (172596, 80)\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\n\nmy_imputer = SimpleImputer()\nnumerical_cols = [cname for cname in X_train.columns if \n                X_train[cname].dtype in ['int64', 'float64']]\n\ncategorical_cols = [cname for cname in X_train.columns if \n                    X_train[cname].dtype == 'object']\n\nnumerical_imputer = SimpleImputer(strategy='mean')\nX_train_numerical = X_train[numerical_cols].copy()\nX_valid_numerical = X_valid[numerical_cols].copy()\nX_train_numerical = numerical_imputer.fit_transform(X_train_numerical)\nX_valid_numerical = numerical_imputer.transform(X_valid_numerical)\n\n# Preprocessing for categorical data\ncategorical_imputer = SimpleImputer(strategy='most_frequent')\nX_train_categorical = X_train[categorical_cols].copy()\nX_valid_categorical = X_valid[categorical_cols].copy()\nX_train_categorical = categorical_imputer.fit_transform(X_train_categorical)\nX_valid_categorical = categorical_imputer.transform(X_valid_categorical)\n\n# Convert back to DataFrame\n\nX_train_numerical = pd.DataFrame(X_train_numerical, columns=numerical_cols)\nX_train_categorical = pd.DataFrame(X_train_categorical, columns=categorical_cols)\nX_valid_numerical = pd.DataFrame(X_valid_numerical, columns=numerical_cols)\nX_valid_categorical = pd.DataFrame(X_valid_categorical, columns=categorical_cols)\n\n\n# Now you can combine the numerical and categorical data\nX_train = pd.concat([X_train_numerical, X_train_categorical], axis=1)\nX_valid =  pd.concat([X_valid_numerical, X_valid_categorical], axis=1)\n","metadata":{"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"missing_val_count_by_column = (X_train.isnull().sum())\nprint(missing_val_count_by_column[missing_val_count_by_column >0])\nmissing_val_count_by_column_valid = (X_valid.isnull().sum())\nprint(missing_val_count_by_column_valid[missing_val_count_by_column_valid >0])\nprint(X_train.shape, X_valid.shape)","metadata":{"execution":{"iopub.status.busy":"2024-02-25T19:39:13.409298Z","iopub.execute_input":"2024-02-25T19:39:13.409591Z","iopub.status.idle":"2024-02-25T19:39:14.090468Z","shell.execute_reply.started":"2024-02-25T19:39:13.409565Z","shell.execute_reply":"2024-02-25T19:39:14.089416Z"},"trusted":true},"execution_count":79,"outputs":[{"name":"stdout","text":"Series([], dtype: int64)\nSeries([], dtype: int64)\n(517788, 80) (172596, 80)\n","output_type":"stream"}]},{"cell_type":"code","source":"X_train[categorical_cols].head()","metadata":{"execution":{"iopub.status.busy":"2024-02-25T19:39:14.093293Z","iopub.execute_input":"2024-02-25T19:39:14.093745Z","iopub.status.idle":"2024-02-25T19:39:14.204704Z","shell.execute_reply.started":"2024-02-25T19:39:14.093714Z","shell.execute_reply":"2024-02-25T19:39:14.203532Z"},"trusted":true},"execution_count":80,"outputs":[{"execution_count":80,"output_type":"execute_result","data":{"text/plain":"         term grade sub_grade           emp_title emp_length home_ownership  \\\n0   36 months     A        A4          Paralegal      1 year       MORTGAGE   \n1   36 months     D        D2             Teacher  10+ years       MORTGAGE   \n2   36 months     A        A4               owner    4 years       MORTGAGE   \n3   36 months     B        B5             Teacher  10+ years       MORTGAGE   \n4   36 months     A        A4  Senior UX designer   < 1 year       MORTGAGE   \n\n  verification_status   issue_d             purpose                    title  \\\n0        Not Verified  Aug-2017  debt_consolidation       Debt consolidation   \n1            Verified  Jul-2014  debt_consolidation       Debt consolidation   \n2        Not Verified  Mar-2016         credit_card  Credit card refinancing   \n3     Source Verified  Jan-2015  debt_consolidation       Debt consolidation   \n4     Source Verified  Mar-2016         credit_card  Credit card refinancing   \n\n  zip_code addr_state earliest_cr_line initial_list_status last_pymnt_d  \\\n0    740xx         OK         Feb-2003                   f     Dec-2018   \n1    337xx         FL         Mar-1982                   w     Jul-2017   \n2    786xx         TX         Jul-1997                   f     Oct-2017   \n3    780xx         TX         Apr-1998                   f     Jan-2018   \n4    191xx         PA         Jan-2001                   w     Dec-2017   \n\n  last_credit_pull_d application_type disbursement_method debt_settlement_flag  \n0           Dec-2018       Individual                Cash                    N  \n1           Jul-2017       Individual                Cash                    N  \n2           Oct-2017       Individual                Cash                    N  \n3           Dec-2017       Individual                Cash                    N  \n4           Jul-2018       Individual                Cash                    N  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>term</th>\n      <th>grade</th>\n      <th>sub_grade</th>\n      <th>emp_title</th>\n      <th>emp_length</th>\n      <th>home_ownership</th>\n      <th>verification_status</th>\n      <th>issue_d</th>\n      <th>purpose</th>\n      <th>title</th>\n      <th>zip_code</th>\n      <th>addr_state</th>\n      <th>earliest_cr_line</th>\n      <th>initial_list_status</th>\n      <th>last_pymnt_d</th>\n      <th>last_credit_pull_d</th>\n      <th>application_type</th>\n      <th>disbursement_method</th>\n      <th>debt_settlement_flag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>36 months</td>\n      <td>A</td>\n      <td>A4</td>\n      <td>Paralegal</td>\n      <td>1 year</td>\n      <td>MORTGAGE</td>\n      <td>Not Verified</td>\n      <td>Aug-2017</td>\n      <td>debt_consolidation</td>\n      <td>Debt consolidation</td>\n      <td>740xx</td>\n      <td>OK</td>\n      <td>Feb-2003</td>\n      <td>f</td>\n      <td>Dec-2018</td>\n      <td>Dec-2018</td>\n      <td>Individual</td>\n      <td>Cash</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>36 months</td>\n      <td>D</td>\n      <td>D2</td>\n      <td>Teacher</td>\n      <td>10+ years</td>\n      <td>MORTGAGE</td>\n      <td>Verified</td>\n      <td>Jul-2014</td>\n      <td>debt_consolidation</td>\n      <td>Debt consolidation</td>\n      <td>337xx</td>\n      <td>FL</td>\n      <td>Mar-1982</td>\n      <td>w</td>\n      <td>Jul-2017</td>\n      <td>Jul-2017</td>\n      <td>Individual</td>\n      <td>Cash</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>36 months</td>\n      <td>A</td>\n      <td>A4</td>\n      <td>owner</td>\n      <td>4 years</td>\n      <td>MORTGAGE</td>\n      <td>Not Verified</td>\n      <td>Mar-2016</td>\n      <td>credit_card</td>\n      <td>Credit card refinancing</td>\n      <td>786xx</td>\n      <td>TX</td>\n      <td>Jul-1997</td>\n      <td>f</td>\n      <td>Oct-2017</td>\n      <td>Oct-2017</td>\n      <td>Individual</td>\n      <td>Cash</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>36 months</td>\n      <td>B</td>\n      <td>B5</td>\n      <td>Teacher</td>\n      <td>10+ years</td>\n      <td>MORTGAGE</td>\n      <td>Source Verified</td>\n      <td>Jan-2015</td>\n      <td>debt_consolidation</td>\n      <td>Debt consolidation</td>\n      <td>780xx</td>\n      <td>TX</td>\n      <td>Apr-1998</td>\n      <td>f</td>\n      <td>Jan-2018</td>\n      <td>Dec-2017</td>\n      <td>Individual</td>\n      <td>Cash</td>\n      <td>N</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>36 months</td>\n      <td>A</td>\n      <td>A4</td>\n      <td>Senior UX designer</td>\n      <td>&lt; 1 year</td>\n      <td>MORTGAGE</td>\n      <td>Source Verified</td>\n      <td>Mar-2016</td>\n      <td>credit_card</td>\n      <td>Credit card refinancing</td>\n      <td>191xx</td>\n      <td>PA</td>\n      <td>Jan-2001</td>\n      <td>w</td>\n      <td>Dec-2017</td>\n      <td>Jul-2018</td>\n      <td>Individual</td>\n      <td>Cash</td>\n      <td>N</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"X_train['emp_length'].unique()","metadata":{"execution":{"iopub.status.busy":"2024-02-25T19:39:14.206210Z","iopub.execute_input":"2024-02-25T19:39:14.206601Z","iopub.status.idle":"2024-02-25T19:39:14.250970Z","shell.execute_reply.started":"2024-02-25T19:39:14.206571Z","shell.execute_reply":"2024-02-25T19:39:14.249838Z"},"trusted":true},"execution_count":81,"outputs":[{"execution_count":81,"output_type":"execute_result","data":{"text/plain":"array(['1 year', '10+ years', '4 years', '< 1 year', '5 years', '2 years',\n       '7 years', '9 years', '3 years', '8 years', '6 years'],\n      dtype=object)"},"metadata":{}}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import OrdinalEncoder\n#custom_order_grade = ['A', 'B','C','D','E','F','G']\ncustom_order_subgrade = ['A1','A2','A3','A4','A5','B1','B2','B3','B4','B5','C1','C2','C3','C4','C5','D1','D2','D3','D4','D5','E1','E2','E3','E4','E5','F1','F2','F3','F4','F5','G1','G2','G3','G4','G5']\nordinal_encoder = OrdinalEncoder(categories=[custom_order_subgrade])\nX_train['sub_grade'] = ordinal_encoder.fit_transform(X_train[['sub_grade']])\n","metadata":{"execution":{"iopub.status.busy":"2024-02-25T19:39:14.252761Z","iopub.execute_input":"2024-02-25T19:39:14.253249Z","iopub.status.idle":"2024-02-25T19:39:14.405433Z","shell.execute_reply.started":"2024-02-25T19:39:14.253183Z","shell.execute_reply":"2024-02-25T19:39:14.404248Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"X_valid['sub_grade'] = ordinal_encoder.transform(X_valid[['sub_grade']]) \ncustom_order_emp_length = ['< 1 year', '1 year', '2 years', '3 years','4 years',  '5 years','6 years', '7 years','8 years','9 years','10+ years']\nordinal_encoder2 = OrdinalEncoder(categories=[custom_order_emp_length])\nX_train['emp_length'] = ordinal_encoder2.fit_transform(X_train[['emp_length']])\nX_valid['emp_length'] = ordinal_encoder2.transform(X_valid[['emp_length']])\nprint('done')","metadata":{"execution":{"iopub.status.busy":"2024-02-25T19:39:14.407133Z","iopub.execute_input":"2024-02-25T19:39:14.407576Z","iopub.status.idle":"2024-02-25T19:39:14.669963Z","shell.execute_reply.started":"2024-02-25T19:39:14.407537Z","shell.execute_reply":"2024-02-25T19:39:14.668806Z"},"trusted":true},"execution_count":83,"outputs":[{"name":"stdout","text":"done\n","output_type":"stream"}]},{"cell_type":"code","source":"X_valid['sub_grade'].head()","metadata":{"execution":{"iopub.status.busy":"2024-02-25T19:39:14.671500Z","iopub.execute_input":"2024-02-25T19:39:14.671944Z","iopub.status.idle":"2024-02-25T19:39:14.680947Z","shell.execute_reply.started":"2024-02-25T19:39:14.671904Z","shell.execute_reply":"2024-02-25T19:39:14.679058Z"},"trusted":true},"execution_count":84,"outputs":[{"execution_count":84,"output_type":"execute_result","data":{"text/plain":"0    16.0\n1    11.0\n2    11.0\n3     6.0\n4     8.0\nName: sub_grade, dtype: float64"},"metadata":{}}]},{"cell_type":"code","source":"X_train.drop(columns = ['grade'], inplace=True)\nX_valid.drop(columns = ['grade'], inplace=True) # redundant feature with grade\n","metadata":{"execution":{"iopub.status.busy":"2024-02-25T19:39:14.682010Z","iopub.execute_input":"2024-02-25T19:39:14.682399Z","iopub.status.idle":"2024-02-25T19:39:14.977460Z","shell.execute_reply.started":"2024-02-25T19:39:14.682368Z","shell.execute_reply":"2024-02-25T19:39:14.976304Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"X_valid.shape","metadata":{"execution":{"iopub.status.busy":"2024-02-25T19:39:14.978834Z","iopub.execute_input":"2024-02-25T19:39:14.979183Z","iopub.status.idle":"2024-02-25T19:39:14.986136Z","shell.execute_reply.started":"2024-02-25T19:39:14.979155Z","shell.execute_reply":"2024-02-25T19:39:14.984953Z"},"trusted":true},"execution_count":86,"outputs":[{"execution_count":86,"output_type":"execute_result","data":{"text/plain":"(172596, 79)"},"metadata":{}}]},{"cell_type":"code","source":"# List to store features with unequal unique values\ncolumns_with_different_unique_values = []\n\ncategorical_cols = [cname for cname in X_train.columns if \n                    X_train[cname].dtype == 'object']\n#print(categorical_cols)\n# Iterate over each feature\nfor col in categorical_cols:\n    # Get unique values of the feature in train and validation sets\n    train_unique_values = set(X_train[col].unique())\n    valid_unique_values = set(X_valid[col].unique())\n    #print(col,X_train[col].nunique() ,X_valid[col].nunique())\n    \n    # Check if unique values are not equal\n    if not valid_unique_values.issubset(train_unique_values):\n        columns_with_different_unique_values.append(col)\n        print(col, X_train[col].nunique(),X_valid[col].nunique())\n\n\n# Print features with unequal unique values\nprint(\"Features with unequal unique values between X_train and X_valid:\")\nprint(columns_with_different_unique_values)","metadata":{"execution":{"iopub.status.busy":"2024-02-25T19:49:19.667495Z","iopub.execute_input":"2024-02-25T19:49:19.667893Z","iopub.status.idle":"2024-02-25T19:49:20.836969Z","shell.execute_reply.started":"2024-02-25T19:49:19.667862Z","shell.execute_reply":"2024-02-25T19:49:20.835759Z"},"trusted":true},"execution_count":91,"outputs":[{"name":"stdout","text":"emp_title 175168 70130\ntitle 27117 10637\nzip_code 909 886\nearliest_cr_line 709 670\nlast_pymnt_d 133 131\nlast_credit_pull_d 132 128\nFeatures with unequal unique values between X_train and X_valid:\n['emp_title', 'title', 'zip_code', 'earliest_cr_line', 'last_pymnt_d', 'last_credit_pull_d']\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}